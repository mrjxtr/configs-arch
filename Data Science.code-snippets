{
	// Misc
	"Create code block header": {
		"prefix": "#",
		"scope":"python",
		"body": [
			"#$1 ------------------------------------------------------",
			"#$1 $2",
			"#$1 ------------------------------------------------------"
		],
		"description": "Create a section header"
	},
	
	// Pandas
	"Read from ../data/..": {
		"prefix": "rd",
		"scope":"python",
		"body": [
			"import os",
			"",
			"import numpy as np",
			"import pandas as pd",
			"",
			"# Load data",
			"script_dir = os.path.dirname(__file__)",
			"data_path = os.path.abspath(os.path.join(script_dir, '../data/$1/$2'))",
			"",
			"# Read data into a DataFrame",
			"df = pd.read_$3(data_path)",
			"",
			"$0"
		],
		"description": "Read data to create pd.DataFrame"
	},
	"Read from ../data/.. by chunks": {
		"prefix": "rdb",
		"scope":"python",
		"body": [
			"import os",
			"",
			"import numpy as np",
			"import pandas as pd",
			"",
			"# define path to data",
			"script_dir = os.path.dirname(__file__)",
			"data_path = os.path.abspath(os.path.join(script_dir, '../data/$1/$2'))",
			"",
			"for chunk in pd.read_$3(data_path, chunksize=1000):",
			"    # Perform some operation on the chunk",
			"    ...",
			"    print(chunk.head())",
			"",
			"$0"
		],
		"description": "Read data to by chunks to create pd.DataFrame or perform some operations"
	},
	"Read from ../data/.. for plots": {
		"prefix": "rdp",
		"scope":"python",
		"body": [
			"import os",
			"import sys",
			"",
			"import matplotlib.pyplot as plt",
			"import numpy as np",
			"import pandas as pd",
			"import seaborn as sns",
			"",
			"# Load configuration for plots and exports",
			"import utility.plots_cfg as plt_c",
			"from utility.plots_save import export_figs",
			"",
			"# Load configuration for plots",
			"plt_c.load_cfg()",
			"",
			"# Load data",
			"script_dir = os.path.dirname(__file__)",
			"data_path = os.path.abspath(os.path.join(script_dir, '../data/$1/$2'))",
			"",
			"# Read data into a DataFrame",
			"df = pd.read_$3(data_path)",
			"",
			"$0"
		],
		"description": "Read data for exploratory and results-oriented visualizations"
	},
	"Read from ../data/.. for modeling": {
		"prefix": "rdm",
		"scope":"python",
		"body": [
			"import os",
			"",
			"import matplotlib.pyplot as plt",
			"import numpy as np",
			"import pandas as pd",
			"import seaborn as sns",
			"",
			"# Load configuration for plots and exports",
			"import utility.plots_cfg as plt_c",
			"from utility.plots_save import export_figs",
			"",
			"# Load configuration for plots",
			"plt_c.load_cfg()",
			"",
			"# Load data",
			"script_dir = os.path.dirname(__file__)",
			"data_path = os.path.abspath(os.path.join(script_dir, '../../data/processed/$1'))",
			"",
			"# Read data into a DataFrame",
			"df = pd.read_$3(data_path)",
			"",
			"$0"
		],
		"description": "Read data for data modeling"
	},

	// Seaborn

	// Scikit-Learn
	"Train-Test Split": {
		"prefix": "sk-tt",
		"scope": "python",
		"body": [
			"from sklearn.model_slection import train_test_split",
			"",
			"# Define the columns for the split",
			"categorical_cols = [$1]",
			"feature_cols = [$2]",
			"",
			"# Define the target column",
			"target = '$3'",
			"",
			"# Create the feature matrix and target vector",
			"X = df.drop(feature_cols).copy()",
			"y = df[target]",
			"",
			"# Convert categorical columns to category type",
			"X[categorical_cols] = X[categorical_cols].astype('category')",
			"X = pd.get_dummies(X, columns=categorical_cols, dtype=int)",
			"",
			"# Perform the train-test split",
			"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)",
			"",
			"$0"
		],
	"description": "Create a train test split with Scikit-Learn"
	},
	"Linear Regression Model": {
		"prefix": "sk-lr",
		"scope": "python",
		"body": [
			"import numpy as np",
			"from sklearn.linear_model import LinearRegression",
			"from sklearn.metrics import mean_squared_error, r2_score",
			"from sklearn.model_selection import train_test_split",
			"",
			"# Define the columns for the split",
			"categorical_cols = [$1]",
			"feature_cols = [$2]",
			"",
			"# Define the target column",
			"target = '$3'",
			"",
			"# Create the feature matrix and target vector",
			"X = df.drop(feature_cols).copy()",
			"y = df[target]",
			"",
			"# Convert categorical columns to category type",
			"X[categorical_cols] = X[categorical_cols].astype('category')",
			"X = pd.get_dummies(X, columns=categorical_cols, dtype=int)",
			"",
			"# Perform the train-test split",
			"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)",
			"",
			"# Setting hyperparameters manually",
			"hyper_params = {",
			"    'max_depth': 15,",
			"    'min_samples_leaf': 1,",
			"    'min_samples_split': 2,",
			"    'n_estimators': 100,",
			"}",
			"",
			"# Training the model with manually set hyperparameters",
			"model = RandomForestRegressor(**hyper_params)",
			"model.fit(X_train, y_train)",
			"",
			"# Make predictions",
			"y_pred = model.predict(X_test)",
			"",
			"# Evaluate the model",
			"test_score = model.score(X_test, y_test)",
			"rmse = np.sqrt(mean_squared_error(y_test, y_pred))",
			"r2 = r2_score(y_test, y_pred)",
			"",
			"print('Test Score:', test_score)",
			"print('Root Mean Squared Error (RMSE):', rmse)",
			"print('R2 Score:',r2)",
			"",
			"$0"
		],
	"description": "Create a linear regression model with Scikit-Learn"
	},
	"Create a Grid Search":{
		"prefix": "sk-gs",
		"scope": "python",
		"body": [
			"import numpy as np",
			"from sklearn.$1 import $2",
			"from sklearn.metrics import mean_squared_error, r2_score",
			"from sklearn.model_selection import GridSearchCV, train_test_split",
			"",
			"# Define the columns for the split",
			"categorical_cols = []",
			"feature_cols = []",
			"",
			"# Define the target column",
			"target = ''",
			"",
			"# Create the feature matrix and target vector",
			"X = df.drop(feature_cols).copy()",
			"y = df[target]",
			"",
			"# Convert categorical columns to category type",
			"X[categorical_cols] = X[categorical_cols].astype('category')",
			"X = pd.get_dummies(X, columns=categorical_cols, dtype=int)",
			"",
			"# Perform the train-test split",
			"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)",
			"",
			"# Define the parameter grid for Grid Search",
			"param_grid = {",
			"    'max_depth': [10, 15, 20, 25, 30],",
			"    'min_samples_leaf': [1, 2, 4, 6, 8],",
			"    'min_samples_split': [2, 5, 10],",
			"    'n_estimators': [100, 200, 300, 400],",
			"}",
			"",
			"# Initialize the model for Grid Search",
			"model = $2(random_state=123)",
			"",
			"# Set up Grid Search with 5-fold cross-validation",
			"grid_search = GridSearchCV(",
			"    estimator=model,",
			"    param_grid=param_grid,",
			"    scoring='neg_mean_squared_error',",
			"    cv=5,",
			"    n_jobs=-1",
			"    verbose=1,",
			"",
			"# Fit Grid Search to the training data",
			"grid_search.fit(X_train, y_train)",
			"",
			"# Print the best parameters and best score",
			"print('Best Parameters:', grid_search.best_params_)",
			"print('Best Score:', grid_search.best_score_)",
			"",
			"# Use the best model from Grid Search to make predictions",
			"best_model = grid_search.best_estimator_",
			"best_model.fit(X_train, y_train)",
			"",
			"# Make predictions",
			"y_pred = best_model.predict(X_test)",
			"",
			"# Evaluate the model",
			"test_score = best_model.score(X_test, y_test)",
			"rmse = np.sqrt(mean_squared_error(y_test, y_pred))",
			"r2 = r2_score(y_test, y_pred)",
			"",
			"print('Test Score:', test_score)",
			"print('Root Mean Squared Error (RMSE):', rmse)",
			"print('R2 Score:', r2)",
			"",
			"$0"
		],
	"description": "Create a Grid Search for best hyperparams for specific model with Scikit-Learn"
	},

	// Exporting models (JpbLib/Pickle)
	"Export Model": {
		"prefix": "xpm",
		"scope": "python",
		"body": [
			"import joblib",
			"",
			"# Export the model",
			"model_path = os.path.join(script_dir, '../models/$1.$2')",
			"dump($3, model_path)",
			"print(f'Model saved at {model_path}')",
			"",
			"$0"
		],
	},
	
	// Tensorflow

	// Exporting data
	"Export to ../data/..": {
		"prefix": "xpd",
		"scope":"python",
		"body": [
			"df_cleaned = $1.copy()",
			"",
			"# Export data into data folder",
			"export_path = os.path.abspath(os.path.join(script_dir,'../data/$2/$3'))",
			"df_cleaned.to_$4(export_path, index=$5)",
			"print(f'Data exported to {export_path}')",
			"",
			"$0"
		],
		"description": "Export data into data folder"
	},
	"Export to ../reports/figures": {
		"prefix": "xpf",
		"scope":"python",
		"body": [
			"from utility.save_plots import export_figs",
			"",
			"# Path for exporting figures",
			"script_dir = os.path.dirname(__file__)",
			"export_dir: str = os.path.abspath(os.path.join(script_dir, '../reports/figures/'))",
			"figures = [",
			"    (fig$1, '$2.png'),",
			"    (fig$3, '$4.png'),",
			"    (fig$5, '$6.png'),",
			"    (fig$7, '$8.png'),$9",
			"]",
			"",
			"# Export the figures",
			"for index, (fig, filename) in enumerate(figures, start=1):",
			"    export_figs(export_dir, fig, index, filename)",
			"print(f'All figures saved to {export_dir}')",
			"",
			"$0"
		],
		"description": "Save all listed plots to figures folder"
	},
}
